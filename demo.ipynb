{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jukit_cell_id": "FHk2C2mAci"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded airavata_jupyter_magic (2.0.12) \n",
            "(current runtime = local)\n",
            "\n",
            "  %authenticate                      -- Authenticate to access high-performance runtimes.\n",
            "  %request_runtime <rt> [args]       -- Request a runtime named <rt> with configuration <args>. Call multiple times to request multiple runtimes.\n",
            "  %restart_runtime <rt>              -- Restart runtime <rt>. Run this if you install new dependencies or if the runtime hangs.\n",
            "  %stop_runtime <rt>                 -- Stop runtime <rt> when no longer needed.\n",
            "  %switch_runtime <rt>               -- Switch active runtime to <rt>. All subsequent executions will use this runtime.\n",
            "  %%run_on <rt>                      -- Force a cell to always execute on <rt>, regardless of the active runtime.\n",
            "  %stat_runtime <rt>                 -- Show the status of runtime <rt>.\n",
            "  %copy_data <r1:file1> <r2:file2>   -- Copy <file1> in <r1> to <file2> in <r2>.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#%pip install --force-reinstall -q \"airavata-python-sdk[notebook]\"\n",
        "import airavata_jupyter_magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jukit_cell_id": "VonilTFkTU"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4294e0b279241cd9c87e387a3f0106d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticated.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Authenticated.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jukit_cell_id": "1sXw3fhOc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requesting runtime=hpc_cpu\n",
            "cpuCount: 4\n",
            "experimentName: CS_Agent\n",
            "group: Default\n",
            "libraries:\n",
            "- numpy=2.2.5\n",
            "- pandas=2.2.3\n",
            "- pip\n",
            "- psycopg2=2.9.9\n",
            "- postgresql=17.4\n",
            "- pytest\n",
            "- python=3.10\n",
            "- psi4=1.9.1\n",
            "- pytorch-cpu=2.5.1\n",
            "- jupyter=1.1.1\n",
            "- requests\n",
            "- setuptools\n",
            "- torchaudio=2.5.1\n",
            "- torchvision=0.20.1\n",
            "- pytorch_geometric=2.6.1\n",
            "- pytorch_scatter=2.1.2=cpu*\n",
            "- pytorch-minimize=0.0.2\n",
            "- matplotlib=3.10.1\n",
            "- pydantic=1\n",
            "- scipy=1.15.*\n",
            "- tqdm\n",
            "memory: 8000\n",
            "mounts:\n",
            "- cybershuttle-reference:/cybershuttle_data/cybershuttle-reference\n",
            "nodeCount: 1\n",
            "pip:\n",
            "- cdsg-tools==0.0.2\n",
            "- qm-tools-aw==1.4.5\n",
            "- qcmlforge==0.0.6\n",
            "- qcfractal==0.59\n",
            "- qcmanybody\n",
            "- qcfractalcompute==0.59\n",
            "queue: shared\n",
            "remoteCluster: expanse\n",
            "wallTime: 60\n",
            "\n",
            "Requested runtime=hpc_cpu. state=CONFIGURING_WORKSPACE\n",
            "Switched to runtime=hpc_cpu.\n"
          ]
        }
      ],
      "source": [
        "%request_runtime hpc_cpu --file=cybershuttle.yml --walltime=60 --use=expanse:shared\n",
        "%switch_runtime hpc_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apnet2_transfer_learning.pt  __init__.py            qcfractal_server.log\n",
            "combined_df_subset_358.pkl   LICENSE                README.md\n",
            "cybershuttle.yml             main.py                \u001b[0m\u001b[01;35mS22-IE-AP2-dAP2_violin.png\u001b[0m\n",
            "\u001b[01;34mdata_dir\u001b[0m/                    notes.md               \u001b[01;35mS22-IE-AP2_violin.png\u001b[0m\n",
            "demo.html                    \u001b[01;34mog_qcfractal\u001b[0m/          \u001b[01;35mS22-IE_violin.png\u001b[0m\n",
            "demo.ipynb                   \u001b[01;34mparsl_run_dir\u001b[0m/         s22.py\n",
            "demo_og.py                   \u001b[01;34m__pycache__\u001b[0m/           setup_qcfractal.py\n",
            "demo.py                      \u001b[01;34mqcfractal\u001b[0m/             timer.dat\n",
            "environment.yml              qcfractal_compute.log  \u001b[01;34mtmp\u001b[0m/\n",
            "[Errno 2] No such file or directory: '/workspace'\n",
            "/home/amwalla3/gits/cybershuttle_demo\n",
            "apnet2_transfer_learning.pt  __init__.py            qcfractal_server.log\n",
            "combined_df_subset_358.pkl   LICENSE                README.md\n",
            "cybershuttle.yml             main.py                \u001b[0m\u001b[01;35mS22-IE-AP2-dAP2_violin.png\u001b[0m\n",
            "\u001b[01;34mdata_dir\u001b[0m/                    notes.md               \u001b[01;35mS22-IE-AP2_violin.png\u001b[0m\n",
            "demo.html                    \u001b[01;34mog_qcfractal\u001b[0m/          \u001b[01;35mS22-IE_violin.png\u001b[0m\n",
            "demo.ipynb                   \u001b[01;34mparsl_run_dir\u001b[0m/         s22.py\n",
            "demo_og.py                   \u001b[01;34m__pycache__\u001b[0m/           setup_qcfractal.py\n",
            "demo.py                      \u001b[01;34mqcfractal\u001b[0m/             timer.dat\n",
            "environment.yml              qcfractal_compute.log  \u001b[01;34mtmp\u001b[0m/\n",
            "Copying from local:setup_qcfractal.py to hpc_cpu:setup_qcfractal.py\n",
            "Pushing local:setup_qcfractal.py to remote:setup_qcfractal.py\n",
            "[200] Uploaded local:setup_qcfractal.py to remote:setup_qcfractal.py\n",
            "Copying from local:__init__.py to hpc_cpu:__init__.py\n",
            "Pushing local:__init__.py to remote:__init__.py\n",
            "[200] Uploaded local:__init__.py to remote:__init__.py\n"
          ]
        }
      ],
      "source": [
        "%ls\n",
        "%cd /workspace\n",
        "%ls\n",
        "%copy_data source=local:setup_qcfractal.py target=hpc_cpu:setup_qcfractal.py\n",
        "%copy_data source=local:__init__.py target=hpc_cpu:__init__.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "tveJZTmZdq"
      },
      "source": [
        "# QCArchive+QCMLForge Demo with CyberShuttle\n",
        "\n",
        "The first half of this demo shows how to use QCArchive to setup a dataset\n",
        "and run computations with ease. The compute resource can be local or\n",
        "through CyberShuttle. \n",
        "\n",
        "The second half of this demo shows how one can consume the generated data\n",
        "to train AP-Net2 and dAPNet2 models through QCMLForge. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jukit_cell_id": "sb2BSlStsm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠼\u001b[0m Connecting to=hpc_cpu... status=CONNECTEDWORKSPACE\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[HImports\n"
          ]
        }
      ],
      "source": [
        "import psi4\n",
        "from pprint import pprint as pp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from qm_tools_aw import tools\n",
        "from pprint import pprint as pp\n",
        "# QCElemental Imports\n",
        "from qcelemental.models import Molecule\n",
        "import qcelemental as qcel\n",
        "# Dataset Imports\n",
        "from qcportal import PortalClient\n",
        "from qcportal.singlepoint import SinglepointDataset, SinglepointDatasetEntry, QCSpecification\n",
        "from qcportal.manybody import ManybodyDataset, ManybodyDatasetEntry, ManybodyDatasetSpecification, ManybodySpecification\n",
        "from torch import manual_seed\n",
        "\n",
        "manual_seed(42)\n",
        "\n",
        "h2kcalmol = qcel.constants.hartree2kcalmol\n",
        "print('Imports')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "78H3oHPXBB"
      },
      "source": [
        "# QCArchive Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "BVc6W6uOta"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠹\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H/workspace/qcfractal\n",
            "--------------------------------------------------------------------------------\n",
            "Python executable:  /dev/shm/cybershuttle/envs/18dccede/bin/python3.10\n",
            "QCFractal version:  0.59\n",
            "QCFractal alembic revision:  d5988aa750ae\n",
            "pg_ctl path:  /dev/shm/cybershuttle/envs/18dccede/bin/pg_ctl\n",
            "PostgreSQL server version:  PostgreSQL 17.4 on x86_64-conda-linux-gnu, compiled by x86_64-conda-linux-gnu-cc (conda-forge gcc 13.3.0-2) 13.3.0, 64-bit\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Displaying QCFractal configuration below\n",
            "--------------------------------------------------------------------------------\n",
            "access_log_keep: 0\n",
            "allow_unauthenticated_read: true\n",
            "api:\n",
            "  extra_flask_options: null\n",
            "  extra_waitress_options: null\n",
            "  host: localhost\n",
            "  jwt_access_token_expires: 3600\n",
            "  jwt_refresh_token_expires: 86400\n",
            "  jwt_secret_key: UCTKvPSYoYq-hyxLFHMcXm2ZeHeYtcjYMRj4_uHCcWc\n",
            "  num_threads_per_worker: 4\n",
            "  port: 7778\n",
            "  secret_key: fLBaq06zvUwjyZg_gdk1KJ1cpgx3bQqVopHK9MEaRes\n",
            "  worker_timeout: 120\n",
            "api_limits:\n",
            "  add_molecules: 1000\n",
            "  add_records: 500\n",
            "  get_access_logs: 1000\n",
            "  get_dataset_entries: 2000\n",
            "  get_error_logs: 100\n",
            "  get_internal_jobs: 1000\n",
            "  get_managers: 1000\n",
            "  get_molecules: 1000\n",
            "  get_records: 1000\n",
            "  manager_tasks_claim: 200\n",
            "  manager_tasks_return: 10\n",
            "auto_reset:\n",
            "  compute_lost: 5\n",
            "  enabled: false\n",
            "  random_error: 5\n",
            "  unknown_error: 2\n",
            "base_folder: /workspace/qcfractal\n",
            "database:\n",
            "  base_folder: /workspace/qcfractal\n",
            "  data_directory: /workspace/qcfractal/postgres\n",
            "  database_name: qca\n",
            "  echo_sql: false\n",
            "  full_uri: null\n",
            "  host: localhost\n",
            "  logfile: /workspace/qcfractal/qcfractal_database.log\n",
            "  maintenance_db: postgres\n",
            "  own: true\n",
            "  password: d-OoihV4NzGs2I4cCgg9yvM6BWA3DAKZ2uFfZ-xMFWM\n",
            "  pg_tool_dir: null\n",
            "  pool_size: 5\n",
            "  port: 5433\n",
            "  query: {}\n",
            "  username: qcfractal\n",
            "enable_security: false\n",
            "geoip2_dir: /workspace/qcfractal/geoip2\n",
            "geoip2_filename: GeoLite2-City.mmdb\n",
            "heartbeat_frequency: 60\n",
            "heartbeat_frequency_jitter: 0\n",
            "heartbeat_max_missed: 5\n",
            "hide_internal_errors: true\n",
            "homepage_directory: null\n",
            "homepage_redirect_url: null\n",
            "internal_job_keep: 0\n",
            "internal_job_processes: 1\n",
            "log_access: false\n",
            "logfile: null\n",
            "loglevel: INFO\n",
            "max_active_services: 20\n",
            "maxmind_license_key: null\n",
            "name: QCFractal Server\n",
            "s3:\n",
            "  access_key_id: null\n",
            "  bucket_map:\n",
            "    dataset_attachment: dataset_attachment\n",
            "  enabled: false\n",
            "  endpoint_url: null\n",
            "  passthrough: false\n",
            "  secret_access_key: null\n",
            "  verify: true\n",
            "service_frequency: 5\n",
            "strict_queue_tags: false\n",
            "temporary_dir: /scratch/tmp\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QCFractal setup complete\n",
            "To start the server run:\n",
            "  qcfractal-server --config=/workspace/qcfractal/qcfractal_config.yaml start\n",
            "To start the compute manager run:\n",
            "  qcfractal-compute-manager --config=/workspace/qcfractal/resources.yml\n"
          ]
        }
      ],
      "source": [
        "from setup_qcfractal import setup_qcarchive_qcfractal\n",
        "import os\n",
        "\n",
        "setup_qcarchive_qcfractal(\n",
        "    QCF_BASE_FOLDER=os.path.join(os.getcwd(), \"qcfractal\"),\n",
        "    start=False,\n",
        "    reset=False,\n",
        "    db_config={\n",
        "        \"name\": None,\n",
        "        \"enable_security\": \"false\",\n",
        "        \"allow_unauthenticated_read\": None,\n",
        "        \"logfile\": None,\n",
        "        \"loglevel\": None,\n",
        "        \"service_frequency\": 5,\n",
        "        \"max_active_services\": None,\n",
        "        \"heartbeat_frequency\": 60,\n",
        "        \"log_access\": None,\n",
        "        \"database\": {\n",
        "            \"base_folder\": None,\n",
        "            \"host\": None,\n",
        "            \"port\": 5433,\n",
        "            \"database_name\": \"qca\",\n",
        "            \"username\": None,\n",
        "            \"password\": None,\n",
        "            \"own\": None,\n",
        "        },\n",
        "        \"api\": {\n",
        "            \"host\": None,\n",
        "            \"port\": 7778,\n",
        "            \"secret_key\": None,\n",
        "            \"jwt_secret_key\": None,\n",
        "        },\n",
        "    },\n",
        "    resources_config={\n",
        "            \"update_frequency\": 5,\n",
        "            \"cores_per_worker\": 8,\n",
        "            \"max_workers\": 3,\n",
        "            \"memory_per_worker\": 20,\n",
        "    },\n",
        "    conda_env=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠹\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[Hpg_ctl (PostgreSQL) 17.4\n",
            "postgres\n",
            "qcfractal_config.yaml\n",
            "qcfractal_database.log\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pg_ctl --version\n",
        "ls /workspace/qcfractal\n",
        "#pg_ctl -D /workspace/qcfractal/postgres stop -m immediate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jukit_cell_id": "CwEhpqwLXX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠼\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H0\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system = os.system\n",
        "!qcfractal-server --config=`pwd`/qcfractal/qcfractal_config.yaml start &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "jukit_cell_id": "3HjtiyIuFg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠹\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H[2025-04-30 16:51:55 PDT] (MainProcess     )     INFO: qcfractal.qcfractal_server_cli: Checking the PostgreSQL connection...\n",
            "[2025-04-30 16:51:55 PDT] (MainProcess     )     INFO: PostgresHarness: /dev/shm/cybershuttle/envs/18dccede/bin\n",
            "\n",
            "[2025-04-30 16:51:55 PDT] (MainProcess     )     INFO: PostgresHarness: Using Postgres tools found via pg_config located in /dev/shm/cybershuttle/envs/18dccede/bin\n",
            "[2025-04-30 16:51:55 PDT] (MainProcess     )     INFO: PostgresHarness: pg_ctl (PostgreSQL) 17.4\n",
            "\n",
            "[2025-04-30 16:51:55 PDT] (MainProcess     )     INFO: PostgresHarness: Postgresql version found: pg_ctl (PostgreSQL) 17.4\n",
            "[2025-04-30 16:51:55 PDT] (MainProcess     )     INFO: PostgresHarness: Starting the PostgreSQL instance\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: PostgresHarness: waiting for server to start..... done\n",
            "server started\n",
            "\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: PostgresHarness: pg_ctl: server is running (PID: 608945)\n",
            "/dev/shm/cybershuttle/envs/18dccede/bin/postgres \"-D\" \"/workspace/qcfractal/postgres\"\n",
            "\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: PostgresHarness: PostgreSQL successfully started in a background process\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: PostgresHarness: Started a postgres instance for uri postgresql://qcfractal:********@localhost:5433/qca\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: PostgresHarness: Postgres instance serving uri postgresql://qcfractal:********@localhost:5433/qca appears to be up and running\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: alembic.runtime.migration: Context impl PostgresqlImpl.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: alembic.runtime.migration: Will assume transactional DDL.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: fractal_flask_app: Creating flask app\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: SQLAlchemySocket: SQLAlchemy attempt to connect to postgresql://qcfractal:********@localhost:5433/qca.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: SQLAlchemySocket: Connected SQLAlchemy to DB dialect postgresql with driver psycopg2\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: alembic.runtime.migration: Context impl PostgresqlImpl.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: alembic.runtime.migration: Will assume transactional DDL.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: qcfractal.components.external_files.socket: S3 service for external files is not configured\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: SQLAlchemySocket: SQLAlchemy attempt to connect to postgresql://qcfractal:********@localhost:5433/qca.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: SQLAlchemySocket: Connected SQLAlchemy to DB dialect postgresql with driver psycopg2\n",
            "[2025-04-30 16:51:57 PDT] (Process-1       )     INFO: waitress: Serving on http://127.0.0.1:7778\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: alembic.runtime.migration: Context impl PostgresqlImpl.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: alembic.runtime.migration: Will assume transactional DDL.\n",
            "[2025-04-30 16:51:57 PDT] (MainProcess     )     INFO: qcfractal.components.external_files.socket: S3 service for external files is not configured\n",
            "[2025-04-30 16:51:58 PDT] (Process-2       )     INFO: internal_job_runner:4bb8e226-98dd-4473-81f9-3f668e5e985a: running job iterate_services id=1 scheduled_date=2025-04-30 16:51:57.588781-07:00\n",
            "[2025-04-30 16:51:58 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 16:51:58 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "[2025-04-30 16:51:58 PDT] (Process-2       )     INFO: internal_job_runner:4bb8e226-98dd-4473-81f9-3f668e5e985a: running job check_manager_heartbeats id=2 scheduled_date=2025-04-30 16:51:57.740390-07:00\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system = os.system\n",
        "!qcfractal-compute-manager --config=`pwd`/qcfractal/resources.yml &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠹\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        sh: 1: conda: not found\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32512\n"
          ]
        }
      ],
      "source": [
        "!conda "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "2gmdKuBAuk"
      },
      "outputs": [],
      "source": [
        "# NOTE kill server when finished by removing the # and executing:\n",
        "# !ps aux | grep qcfractal | awk '{ print $2 }' | xargs kill -9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!qcfractal-server --config=`pwd`/qcfractal/qcfractal_config.yaml init-db\n",
        "!qcfractal-server --config=`pwd`/qcfractal/qcfractal_config.yaml --help\n",
        "!qcfractal-server --config=`pwd`/qcfractal/qcfractal_config.yaml start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠼\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "for pid in /proc/[0-9]*; do\n",
        "    echo \"${pid##*/}\" `cat ${pid}/comm` > procs.txt\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠹\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H256\n"
          ]
        }
      ],
      "source": [
        "!grep -e 'postgres' ./procs.txt\n",
        "!grep -e 'qcfractal' ./procs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[Hxargs: kill: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#!grep -e 'postgres' ./procs.txt | awk '{ print $1 }' | xargs kill -9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠸\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H[2025-04-30 16:52:00 PDT]     INFO: qcfractalcompute.config: Reading configuration data from /workspace/qcfractal/resources.yml\n",
            "**********\n",
            "Logging to file /workspace/qcfractal/qcfractal-manager.log, logging level INFO\n",
            "**********\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Traceback (most recent call last):\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/bin/qcfractal-compute-manager\", line 8, in <module>\n",
              "    sys.exit(main())\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/compute_manager_cli.py\", line 50, in main\n",
              "    manager = ComputeManager(manager_config)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/compute_manager.py\", line 151, in __init__\n",
              "    self.app_manager = AppManager(self.manager_config)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/apps/app_manager.py\", line 113, in __init__\n",
              "    qcengine_functions = discover_programs_conda(conda_env)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/apps/app_manager.py\", line 33, in discover_programs_conda\n",
              "    result = subprocess.check_output(cmd, universal_newlines=True, cwd=tmpdir)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 421, in check_output\n",
              "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 503, in run\n",
              "    with Popen(*popenargs, **kwargs) as process:\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 971, in __init__\n",
              "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n",
              "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
              "FileNotFoundError: [Errno 2] No such file or directory: 'conda'\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-04-30 16:52:03 PDT] (Process-2       )     INFO: internal_job_runner:4bb8e226-98dd-4473-81f9-3f668e5e985a: running job iterate_services id=5 scheduled_date=2025-04-30 16:52:03.414367-07:00\n",
            "[2025-04-30 16:52:03 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 16:52:03 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "[2025-04-30 16:52:08 PDT] (Process-2       )     INFO: internal_job_runner:4bb8e226-98dd-4473-81f9-3f668e5e985a: running job iterate_services id=7 scheduled_date=2025-04-30 16:52:08.695165-07:00\n",
            "[2025-04-30 16:52:08 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 16:52:08 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "geoip2\n",
            "postgres\n",
            "qcfractal-manager.log\n",
            "qcfractal_config.yaml\n",
            "qcfractal_database.log\n",
            "resources.yml\n",
            "worker.sh\n",
            "2025-04-30 16:48:20.095 PDT [608564] LOG:  starting PostgreSQL 17.4 on x86_64-conda-linux-gnu, compiled by x86_64-conda-linux-gnu-cc (conda-forge gcc 13.3.0-2) 13.3.0, 64-bit\n",
            "2025-04-30 16:48:20.095 PDT [608564] LOG:  listening on IPv4 address \"127.0.0.1\", port 5433\n",
            "2025-04-30 16:48:20.507 PDT [608564] LOG:  listening on Unix socket \"/workspace/qcfractal/postgres/sock/.s.PGSQL.5433\"\n",
            "2025-04-30 16:48:20.702 PDT [608567] LOG:  database system was shut down at 2025-04-30 16:47:37 PDT\n",
            "2025-04-30 16:48:20.876 PDT [608564] LOG:  database system is ready to accept connections\n",
            "2025-04-30 16:48:20.975 PDT [608571] FATAL:  database \"qca\" does not exist\n",
            "2025-04-30 16:48:35.356 PDT [608564] LOG:  received fast shutdown request\n",
            "2025-04-30 16:48:35.592 PDT [608564] LOG:  aborting any active transactions\n",
            "2025-04-30 16:48:35.593 PDT [608564] LOG:  background worker \"logical replication launcher\" (PID 608570) exited with exit code 1\n",
            "2025-04-30 16:48:35.593 PDT [608565] LOG:  shutting down\n",
            "2025-04-30 16:48:35.863 PDT [608565] LOG:  checkpoint starting: shutdown immediate\n",
            "2025-04-30 16:49:36.543 PDT [608655] FATAL:  the database system is shutting down\n",
            "2025-04-30 16:49:36.544 PDT [608656] FATAL:  the database system is shutting down\n",
            "2025-04-30 16:50:09.980 PDT [608565] LOG:  checkpoint complete: wrote 1180 buffers (7.2%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.083 s, sync=93.436 s, total=94.387 s; sync files=770, longest=86.900 s, average=0.122 s; distance=6635 kB, estimate=6635 kB; lsn=0/1B65A58, redo lsn=0/1B65A58\n",
            "2025-04-30 16:50:10.021 PDT [608564] LOG:  database system is shut down\n",
            "2025-04-30 16:50:53.123 PDT [608869] LOG:  starting PostgreSQL 17.4 on x86_64-conda-linux-gnu, compiled by x86_64-conda-linux-gnu-cc (conda-forge gcc 13.3.0-2) 13.3.0, 64-bit\n",
            "2025-04-30 16:50:53.123 PDT [608869] LOG:  listening on IPv4 address \"127.0.0.1\", port 5433\n",
            "2025-04-30 16:51:02.572 PDT [608869] LOG:  listening on Unix socket \"/workspace/qcfractal/postgres/sock/.s.PGSQL.5433\"\n",
            "2025-04-30 16:51:02.793 PDT [608881] LOG:  database system was shut down at 2025-04-30 16:50:09 PDT\n",
            "2025-04-30 16:51:41.929 PDT [608869] LOG:  database system is ready to accept connections\n",
            "2025-04-30 16:51:42.278 PDT [608869] LOG:  received fast shutdown request\n",
            "2025-04-30 16:51:42.376 PDT [608869] LOG:  aborting any active transactions\n",
            "2025-04-30 16:51:42.377 PDT [608869] LOG:  background worker \"logical replication launcher\" (PID 608918) exited with exit code 1\n",
            "2025-04-30 16:51:42.433 PDT [608879] LOG:  shutting down\n",
            "2025-04-30 16:51:42.820 PDT [608879] LOG:  checkpoint starting: shutdown immediate\n",
            "2025-04-30 16:51:46.185 PDT [608879] LOG:  checkpoint complete: wrote 15 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.319 s, sync=2.266 s, total=3.752 s; sync files=6, longest=0.794 s, average=0.378 s; distance=22 kB, estimate=22 kB; lsn=0/1B6B650, redo lsn=0/1B6B650\n",
            "2025-04-30 16:51:46.193 PDT [608869] LOG:  database system is shut down\n",
            "2025-04-30 16:51:56.251 PDT [608945] LOG:  starting PostgreSQL 17.4 on x86_64-conda-linux-gnu, compiled by x86_64-conda-linux-gnu-cc (conda-forge gcc 13.3.0-2) 13.3.0, 64-bit\n",
            "2025-04-30 16:51:56.252 PDT [608945] LOG:  listening on IPv4 address \"127.0.0.1\", port 5433\n",
            "2025-04-30 16:51:56.583 PDT [608945] LOG:  listening on Unix socket \"/workspace/qcfractal/postgres/sock/.s.PGSQL.5433\"\n",
            "2025-04-30 16:51:56.786 PDT [608953] LOG:  database system was shut down at 2025-04-30 16:51:45 PDT\n",
            "2025-04-30 16:51:56.977 PDT [608945] LOG:  database system is ready to accept connections\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "!ls qcfractal/\n",
        "!cat ./qcfractal/qcfractal_database.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "X31FadtbG5"
      },
      "source": [
        "# QCArchive single point example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠋\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H[2025-04-30 14:50:40 PDT]     INFO: qcfractalcompute.config: Reading configuration data from /workspace/qcfractal/resources.yml\n",
            "**********\n",
            "Logging to file /workspace/qcfractal/qcfractal-manager.log, logging level INFO\n",
            "**********\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Traceback (most recent call last):\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/bin/qcfractal-compute-manager\", line 8, in <module>\n",
              "    sys.exit(main())\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/compute_manager_cli.py\", line 50, in main\n",
              "    manager = ComputeManager(manager_config)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/compute_manager.py\", line 151, in __init__\n",
              "    self.app_manager = AppManager(self.manager_config)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/apps/app_manager.py\", line 113, in __init__\n",
              "    qcengine_functions = discover_programs_conda(conda_env)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractalcompute/apps/app_manager.py\", line 33, in discover_programs_conda\n",
              "    result = subprocess.check_output(cmd, universal_newlines=True, cwd=tmpdir)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 421, in check_output\n",
              "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 503, in run\n",
              "    with Popen(*popenargs, **kwargs) as process:\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 971, in __init__\n",
              "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n",
              "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
              "FileNotFoundError: [Errno 2] No such file or directory: 'conda'\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-04-30 14:50:43 PDT] (Process-2       )     INFO: internal_job_runner:55b42e18-773c-438f-93cc-5176b8df6e79: running job iterate_services id=7 scheduled_date=2025-04-30 14:50:43.106314-07:00\n",
            "[2025-04-30 14:50:43 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 14:50:43 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "[2025-04-30 14:50:49 PDT] (Process-2       )     INFO: internal_job_runner:55b42e18-773c-438f-93cc-5176b8df6e79: running job iterate_services id=8 scheduled_date=2025-04-30 14:50:49.051582-07:00\n",
            "[2025-04-30 14:50:49 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 14:50:49 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "[2025-04-30 14:50:54 PDT] (Process-2       )     INFO: internal_job_runner:55b42e18-773c-438f-93cc-5176b8df6e79: running job iterate_services id=9 scheduled_date=2025-04-30 14:50:54.438921-07:00\n",
            "[2025-04-30 14:50:54 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 14:50:54 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "[2025-04-30 14:50:59 PDT] (Process-2       )     INFO: internal_job_runner:55b42e18-773c-438f-93cc-5176b8df6e79: running job iterate_services id=10 scheduled_date=2025-04-30 14:50:59.933422-07:00\n",
            "[2025-04-30 14:51:00 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 14:51:00 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n",
            "[2025-04-30 14:51:05 PDT] (Process-2       )     INFO: internal_job_runner:55b42e18-773c-438f-93cc-5176b8df6e79: running job iterate_services id=11 scheduled_date=2025-04-30 14:51:05.469437-07:00\n",
            "[2025-04-30 14:51:05 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: Iterating on services\n",
            "[2025-04-30 14:51:05 PDT] (Process-2       )     INFO: qcfractal.components.services.socket: After iteration, now 0 running services. Max is 20\n"
          ]
        }
      ],
      "source": [
        "# Establish client connection\n",
        "client = PortalClient(\"http://localhost:7778\", verify=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "jukit_cell_id": "hMCmRgdGJ4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[32m⠸\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
            "\u001b[1A\u001b[2K\u001b[2J\u001b[H[2025-04-30 14:44:40 PDT] (MainProcess     )     INFO: PostgresHarness: waiting for server to start............................................................... stopped waiting\n",
            "\n",
            "[2025-04-30 14:44:40 PDT] (MainProcess     )     INFO: PostgresHarness: pg_ctl: server did not start in time\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Traceback (most recent call last):\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/bin/qcfractal-server\", line 8, in <module>\n",
              "    sys.exit(main())\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractal/qcfractal_server_cli.py\", line 975, in main\n",
              "    server_start(qcf_config)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractal/qcfractal_server_cli.py\", line 414, in server_start\n",
              "    start_database(config, check_revision=True)\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractal/qcfractal_server_cli.py\", line 96, in start_database\n",
              "    pg_harness.ensure_alive()\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractal/postgres_harness.py\", line 240, in ensure_alive\n",
              "    self.start()\n",
              "  File \"/dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcfractal/postgres_harness.py\", line 420, in start\n",
              "    raise RuntimeError(err_msg)\n",
              "RuntimeError: Error starting PostgreSQL. Did you remember to initialize it (qcfractal-server init)?\n",
              "output:\n",
              "waiting for server to start............................................................... stopped waiting\n",
              "\n",
              "stderr:\n",
              "pg_ctl: server did not start in time\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Connection error for http://localhost:7778/api/v1/information: HTTPConnectionPool(host='localhost', port=7778): Max retries exceeded with url: /api/v1/information (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1554dd35d9f0>: Failed to establish a new connection: [Errno 111] Connection refused')) - retrying in 0.49 seconds [1/5]\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Connection error for http://localhost:7778/api/v1/information: HTTPConnectionPool(host='localhost', port=7778): Max retries exceeded with url: /api/v1/information (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1554dd7f7fd0>: Failed to establish a new connection: [Errno 111] Connection refused')) - retrying in 1.01 seconds [2/5]\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Connection error for http://localhost:7778/api/v1/information: HTTPConnectionPool(host='localhost', port=7778): Max retries exceeded with url: /api/v1/information (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1554dd9837c0>: Failed to establish a new connection: [Errno 111] Connection refused')) - retrying in 1.98 seconds [3/5]\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Connection error for http://localhost:7778/api/v1/information: HTTPConnectionPool(host='localhost', port=7778): Max retries exceeded with url: /api/v1/information (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1554dd35d8d0>: Failed to establish a new connection: [Errno 111] Connection refused')) - retrying in 4.01 seconds [4/5]\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <div style=\"\n",
              "                        color: #a71d5d;\n",
              "                        background-color: #fdd;\n",
              "                        border: 1px solid #a71d5d;\n",
              "                        padding: 5px;\n",
              "                        border-radius: 5px;\n",
              "                        font-family: Consolas, 'Courier New', monospace;\n",
              "                        white-space: pre-wrap;\n",
              "                    \">\n",
              "                        Connection error for http://localhost:7778/api/v1/information: HTTPConnectionPool(host='localhost', port=7778): Max retries exceeded with url: /api/v1/information (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1554dd35d4e0>: Failed to establish a new connection: [Errno 111] Connection refused')) - retrying in 8.11 seconds [5/5]\n",
              "                    </div>\n",
              "                    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                <div style=\"\n",
              "                    color: #a71d5d;\n",
              "                    background-color: #fdd;\n",
              "                    border: 1px solid #a71d5d;\n",
              "                    padding: 5px;\n",
              "                    border-radius: 5px;\n",
              "                    font-family: Consolas, 'Courier New', monospace;\n",
              "                \">\n",
              "                    <pre><strong>ConnectionRefusedError: \n",
              "\n",
              "Could not connect to server http://localhost:7778/, please check the address and try again.</strong>\n",
              "                ---------------------------------------------------------------------------\n",
              "ConnectionRefusedError                    Traceback (most recent call last)\n",
              "Cell In[105], line 2\n",
              "      1 # Running a single job\n",
              "----> 2 client = PortalClient(\"http://localhost:7778\", verify=False)\n",
              "      3 mol = Molecule.from_data(\n",
              "      4     \"\"\"\n",
              "      5      0 1\n",
              "   (...)\n",
              "     18 \"\"\"\n",
              "     19 )\n",
              "     21 psi4.set_options(\n",
              "     22     {\"basis\": \"aug-cc-pvdz\", \"scf_type\": \"df\", \"e_convergence\": 6, \"freeze_core\": True}\n",
              "     23 )\n",
              "\n",
              "File /dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcportal/client.py:153, in PortalClient.__init__(self, address, username, password, verify, show_motd, cache_dir, cache_max_size)\n",
              "    120 def __init__(\n",
              "    121     self,\n",
              "    122     address: str,\n",
              "   (...)\n",
              "    129     cache_max_size: int = 0,\n",
              "    130 ) -> None:\n",
              "    131     \"\"\"\n",
              "    132     Parameters\n",
              "    133     ----------\n",
              "   (...)\n",
              "    150         Maximum size of the cache directory\n",
              "    151     \"\"\"\n",
              "--> 153     PortalClientBase.__init__(self, address, username, password, verify, show_motd)\n",
              "    154     self._logger = logging.getLogger(\"PortalClient\")\n",
              "    155     self.cache = PortalCache(address, cache_dir, cache_max_size)\n",
              "\n",
              "File /dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcportal/client_base.py:163, in PortalClientBase.__init__(self, address, username, password, verify, show_motd, information_endpoint)\n",
              "    160     self._jwt_refresh_exp = None\n",
              "    162 # Try to connect and pull the server info\n",
              "--> 163 self.server_info = self.get_server_information()\n",
              "    164 self.server_name = self.server_info[\"name\"]\n",
              "    165 self.api_limits = self.server_info[\"api_limits\"]\n",
              "\n",
              "File /dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcportal/client.py:193, in PortalClient.get_server_information(self)\n",
              "    184 \"\"\"Request general information about the server\n",
              "    185 \n",
              "    186 Returns\n",
              "   (...)\n",
              "    189     Server information.\n",
              "    190 \"\"\"\n",
              "    192 # Request the info, and store here for later use\n",
              "--> 193 return self.make_request(\"get\", \"api/v1/information\", Dict[str, Any])\n",
              "\n",
              "File /dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcportal/client_base.py:495, in PortalClientBase.make_request(self, method, endpoint, response_model, body_model, url_params_model, body, url_params, allow_retries, additional_headers)\n",
              "    492 if isinstance(parsed_url_params, pydantic.BaseModel):\n",
              "    493     parsed_url_params = parsed_url_params.dict()\n",
              "--> 495 r = self._request(\n",
              "    496     method,\n",
              "    497     endpoint,\n",
              "    498     body=serialized_body,\n",
              "    499     url_params=parsed_url_params,\n",
              "    500     allow_retries=allow_retries,\n",
              "    501     additional_headers=additional_headers,\n",
              "    502 )\n",
              "    503 d = deserialize(r.content, r.headers[\"Content-Type\"])\n",
              "    505 if response_model is None:\n",
              "\n",
              "File /dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcportal/client_base.py:440, in PortalClientBase._request(self, method, endpoint, body, url_params, internal_retry, allow_retries, additional_headers)\n",
              "    436 full_uri = self.address + endpoint\n",
              "    437 req = requests.Request(\n",
              "    438     method=method.upper(), url=full_uri, data=body, params=url_params, headers=additional_headers\n",
              "    439 )\n",
              "--> 440 r = self._send_request(req, allow_retries=allow_retries)\n",
              "    442 # If JWT token expired, automatically renew it and retry once. This should have been caught above,\n",
              "    443 # but can happen in rare instances where the token expires between the time we check it and the time\n",
              "    444 # we use it.\n",
              "    445 if internal_retry and (r.status_code == 401) and \"Token has expired\" in r.json()[\"msg\"]:\n",
              "\n",
              "File /dev/shm/cybershuttle/envs/18dccede/lib/python3.10/site-packages/qcportal/client_base.py:345, in PortalClientBase._send_request(self, req, allow_retries)\n",
              "    343     raise ConnectionRefusedError(_ssl_error_msg) from None\n",
              "    344 except requests.exceptions.ConnectionError:\n",
              "--> 345     raise ConnectionRefusedError(_connection_error_msg.format(self.address)) from None\n",
              "    347 if self.debug_requests:\n",
              "    348     pretty_print_response(ret)\n",
              "\n",
              "ConnectionRefusedError: \n",
              "\n",
              "Could not connect to server http://localhost:7778/, please check the address and try again.\n",
              "</pre></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Running a single job\n",
        "client = PortalClient(\"http://localhost:7778\", verify=False)\n",
        "mol = Molecule.from_data(\n",
        "    \"\"\"\n",
        "     0 1\n",
        "     O  -1.551007  -0.114520   0.000000\n",
        "     H  -1.934259   0.762503   0.000000\n",
        "     H  -0.599677   0.040712   0.000000\n",
        "     --\n",
        "     0 1\n",
        "     O   1.350625   0.111469   0.000000\n",
        "     H   1.680398  -0.373741  -0.758561\n",
        "     H   1.680398  -0.373741   0.758561\n",
        "\n",
        "     units angstrom\n",
        "     no_reorient\n",
        "     symmetry c1\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "psi4.set_options(\n",
        "    {\"basis\": \"aug-cc-pvdz\", \"scf_type\": \"df\", \"e_convergence\": 6, \"freeze_core\": True}\n",
        ")\n",
        "\n",
        "client.add_singlepoints(\n",
        "    [mol],\n",
        "    \"psi4\",\n",
        "    driver=\"energy\",\n",
        "    method=\"b3lyp\",\n",
        "    basis=\"aug-cc-pvdz\",\n",
        "    keywords={\"scf_type\": \"df\", \"e_convergence\": 6, \"freeze_core\": True},\n",
        "    tag=\"local\",\n",
        ")\n",
        "\n",
        "# Can print records\n",
        "# for rec in client.query_records():\n",
        "#     pp(rec.dict)\n",
        "#     pp(rec.error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "6DmD5wp1nB"
      },
      "source": [
        "# QCArchive dataset examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "Z0wXrcgRq8"
      },
      "outputs": [],
      "source": [
        "# Creating a QCArchive Dataset...\n",
        "# Load in a dataset from a recent Sherrill work (Levels of SAPT II)\n",
        "df_LoS = pd.read_pickle(\"./combined_df_subset_358.pkl\")\n",
        "print(df_LoS[['Benchmark', 'SAPT2+3(CCD)DMP2 TOTAL ENERGY aqz', 'MP2 IE atz', 'SAPT0 TOTAL ENERGY adz' ]])\n",
        "\n",
        "# Limit to 100 molecules with maximum of 16 atoms to keep computational cost down\n",
        "df_LoS['size'] = df_LoS['atomic_numbers'].apply(lambda x: len(x))\n",
        "df_LoS = df_LoS[df_LoS['size'] <= 16]\n",
        "df_LoS = df_LoS.sample(200, random_state=42, axis=0).copy()\n",
        "df_LoS.reset_index(drop=True, inplace=True)\n",
        "print(df_LoS['size'].describe())\n",
        "\n",
        "# Create QCElemntal Molecules to generate the dataset\n",
        "def qcel_mols(row):\n",
        "    \"\"\"\n",
        "    Convert the row to a qcel molecule\n",
        "    \"\"\"\n",
        "    atomic_numbers = [row['atomic_numbers'][row['monAs']], row['atomic_numbers'][row['monBs']]]\n",
        "    coords = [row['coordinates'][row['monAs']], row['coordinates'][row['monBs']]]\n",
        "    cm = [\n",
        "        [row['monA_charge'], row['monA_multiplicity']],\n",
        "        [row['monB_charge'], row['monB_multiplicity']],\n",
        "     ]\n",
        "    return tools.convert_pos_carts_to_mol(atomic_numbers, coords, cm)\n",
        "df_LoS['qcel_molecule'] = df_LoS.apply(qcel_mols, axis=1)\n",
        "geoms = df_LoS['qcel_molecule'].tolist()\n",
        "ref_IEs = df_LoS['Benchmark'].tolist()\n",
        "sapt0_adz = (df_LoS['SAPT0 TOTAL ENERGY adz'] * h2kcalmol).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "iwmcvViziS"
      },
      "source": [
        "## Singlepoint Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "i8ICwzPWaD"
      },
      "outputs": [],
      "source": [
        "# Create client dataset\n",
        "\n",
        "ds_name = 'S22-singlepoint'\n",
        "client_datasets = [i['dataset_name'] for i in client.list_datasets()]\n",
        "# Check if dataset already exists, if not create a new one\n",
        "if ds_name not in client_datasets:\n",
        "    ds = client.add_dataset(\"singlepoint\", ds_name,\n",
        "                            f\"Dataset to contain {ds_name}\")\n",
        "    print(f\"Added {ds_name} as dataset\")\n",
        "    # Insert entries into dataset\n",
        "    entry_list = []\n",
        "    for idx, mol in enumerate(geoms):\n",
        "        extras = {\n",
        "            \"name\": 'S22-' + str(idx),\n",
        "            \"idx\": idx,\n",
        "        }\n",
        "        mol = Molecule.from_data(mol.dict(), extras=extras)\n",
        "        ent = SinglepointDatasetEntry(name=extras['name'], molecule=mol)\n",
        "        entry_list.append(ent)\n",
        "    ds.add_entries(entry_list)\n",
        "    print(f\"Added {len(entry_list)} molecules to dataset\")\n",
        "else:\n",
        "    ds = client.get_dataset(\"singlepoint\", ds_name)\n",
        "    print(f\"Found {ds_name} dataset, using this instead\")\n",
        "\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "7ZAOPlzuUX"
      },
      "outputs": [],
      "source": [
        "# Can delete the dataset if you want to start over. Need to know dataset_id\n",
        "# client.delete_dataset(dataset_id=ds.id, delete_records=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "dSW1A9HxYB"
      },
      "outputs": [],
      "source": [
        "# Multipole Example\n",
        "# method, basis = \"hf\", \"sto-3g\"\n",
        "#\n",
        "# # Set the QCSpecification (QM interaction energy in our case)\n",
        "# spec = QCSpecification(\n",
        "#     program=\"psi4\",\n",
        "#     driver=\"energy\",\n",
        "#     method=method,\n",
        "#     basis=basis,\n",
        "#     keywords={\n",
        "#         \"d_convergence\": 8,\n",
        "#         \"dft_radial_points\": 99,\n",
        "#         \"dft_spherical_points\": 590,\n",
        "#         \"e_convergence\": 10,\n",
        "#         \"guess\": \"sad\",\n",
        "#         \"mbis_d_convergence\": 9,\n",
        "#         \"mbis_radial_points\": 99,\n",
        "#         \"mbis_spherical_points\": 590,\n",
        "#         \"scf_properties\": [\"mbis_charges\", \"MBIS_VOLUME_RATIOS\"],\n",
        "#         \"scf_type\": \"df\",\n",
        "#     },\n",
        "#     protocols={\"wavefunction\": \"orbitals_and_eigenvalues\"},\n",
        "# )\n",
        "# ds.add_specification(name=f\"psi4/{method}/{basis}\", specification=spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "vMkm00fo00"
      },
      "outputs": [],
      "source": [
        "# SAPT0 Example\n",
        "method, basis = \"SAPT0\", \"cc-pvdz\"\n",
        "\n",
        "# Set the QCSpecification (QM interaction energy in our case)\n",
        "spec = QCSpecification(\n",
        "    program=\"psi4\",\n",
        "    driver=\"energy\",\n",
        "    method=method,\n",
        "    basis=basis,\n",
        "    keywords={\n",
        "        \"scf_type\": \"df\",\n",
        "    },\n",
        ")\n",
        "ds.add_specification(name=f\"psi4/{method}/{basis}\", specification=spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "dwYb9dbQNI"
      },
      "outputs": [],
      "source": [
        "# Run the computations\n",
        "ds.submit()\n",
        "print(f\"Submitted {ds_name} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "2JMCNlehez"
      },
      "outputs": [],
      "source": [
        "# Check the status of the dataset - can repeatedly run this to see the progress\n",
        "ds.status()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "kT14mJyNqJ"
      },
      "source": [
        "## Manybody Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "g31JlHrgso"
      },
      "outputs": [],
      "source": [
        "# Create client dataset\n",
        "ds_name_mb = 'S22-manybody'\n",
        "client_datasets = [i['dataset_name'] for i in client.list_datasets()]\n",
        "# Check if dataset already exists, if not create a new one\n",
        "if ds_name_mb not in client_datasets:\n",
        "    print(\"Setting up new dataset:\", ds_name_mb)\n",
        "    ds_mb = client.add_dataset(\"manybody\", ds_name_mb,\n",
        "                            f\"Dataset to contain {ds_name_mb}\")\n",
        "    print(f\"Added {ds_name_mb} as dataset\")\n",
        "    # Insert entries into dataset\n",
        "    entry_list = []\n",
        "    for idx, mol in enumerate(geoms):\n",
        "        ent = ManybodyDatasetEntry(name=f\"S22-IE-{idx}\", initial_molecule=mol)\n",
        "        entry_list.append(ent)\n",
        "    ds_mb.add_entries(entry_list)\n",
        "    print(f\"Added {len(entry_list)} molecules to dataset\")\n",
        "else:\n",
        "    ds_mb = client.get_dataset(\"manybody\", ds_name_mb)\n",
        "    print(f\"Found {ds_name_mb} dataset, using this instead\")\n",
        "\n",
        "print(ds_mb)\n",
        "\n",
        "# Can delete the dataset if you want to start over. Need to know dataset_id\n",
        "# client.delete_dataset(dataset_id=2, delete_records=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "bYERcUudd0"
      },
      "outputs": [],
      "source": [
        "ds_mb.status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "gauw3VIjl9"
      },
      "outputs": [],
      "source": [
        "# Set multiple levels of theory - you can add/remove levels as you desire.\n",
        "# Computational scaling will get quite expensive with better methods and larger\n",
        "# basis sets\n",
        "\n",
        "methods = [\n",
        "    'hf', 'pbe',\n",
        "]\n",
        "basis_sets = [\n",
        "    '6-31g*'\n",
        "]\n",
        "\n",
        "for method in methods:\n",
        "    for basis in basis_sets:\n",
        "        # Set the QCSpecification (QM interaction energy in our case)\n",
        "        qc_spec_mb = QCSpecification(\n",
        "            program=\"psi4\",\n",
        "            driver=\"energy\",\n",
        "            method=method,\n",
        "            basis=basis,\n",
        "            keywords={\n",
        "                \"d_convergence\": 8,\n",
        "                \"scf_type\": \"df\",\n",
        "            },\n",
        "        )\n",
        "\n",
        "        spec_mb = ManybodySpecification(\n",
        "            program='qcmanybody',\n",
        "            bsse_correction=['cp'],\n",
        "            levels={\n",
        "                1: qc_spec_mb,\n",
        "                2: qc_spec_mb,\n",
        "            },\n",
        "        )\n",
        "        print(\"spec_mb\", spec_mb)\n",
        "\n",
        "        ds_mb.add_specification(name=f\"psi4/{method}/{basis}\", specification=spec_mb)\n",
        "\n",
        "        # Run the computations\n",
        "        ds_mb.submit()\n",
        "        print(f\"Submitted {ds_name} dataset\")\n",
        "# Check the status of the dataset - can repeatedly run this to see the progress\n",
        "ds_mb.status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "qYukdPBXmi"
      },
      "outputs": [],
      "source": [
        "pp(ds.status())\n",
        "pp(ds_mb.status())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "ChCOdcBiXj"
      },
      "outputs": [],
      "source": [
        "pp(ds)\n",
        "pp(ds_mb)\n",
        "pp(ds_mb.computed_properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "xgdzc0Klhx"
      },
      "source": [
        "# Data Assembly\n",
        "\n",
        "While you can execute the following blocks before all computations are complete, it is recommended to wait until all computations are complete to continue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "7RHL31QOoC"
      },
      "outputs": [],
      "source": [
        "# Singlepoint data assemble\n",
        "def assemble_singlepoint_data(record):\n",
        "    record_dict = record.dict()\n",
        "    qcvars = record_dict[\"properties\"]\n",
        "    level_of_theory = f\"{record_dict['specification']['method']}/{record_dict['specification']['basis']}\"\n",
        "    sapt_energies = np.array([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
        "    if \"mbis charges\" in qcvars:\n",
        "        charges = qcvars[\"mbis charges\"]\n",
        "        dipoles = qcvars[\"mbis dipoles\"]\n",
        "        quadrupoles = qcvars[\"mbis quadrupoles\"]\n",
        "        n = len(charges)\n",
        "        charges = np.reshape(charges, (n, 1))\n",
        "        dipoles = np.reshape(dipoles, (n, 3))\n",
        "        quad = np.reshape(quadrupoles, (n, 3, 3))\n",
        "\n",
        "        quad = [q[np.triu_indices(3)] for q in quad]\n",
        "        quadrupoles = np.array(quad)\n",
        "        multipoles = np.concatenate(\n",
        "            [charges, dipoles, quadrupoles], axis=1)\n",
        "        return (\n",
        "        record.molecule,\n",
        "        qcvars['mbis volume ratios'],\n",
        "        qcvars['mbis valence widths'],\n",
        "        qcvars['mbis radial moments <r^2>'],\n",
        "        qcvars['mbis radial moments <r^3>'],\n",
        "        qcvars['mbis radial moments <r^4>'],\n",
        "        record.molecule.atomic_numbers,\n",
        "        record.molecule.geometry * qcel.constants.bohr2angstroms,\n",
        "        multipoles,\n",
        "        int(record.molecule.molecular_charge),\n",
        "        record.molecule.molecular_multiplicity,\n",
        "        sapt_energies,\n",
        "        )\n",
        "    else:\n",
        "        sapt_energies[0] = qcvars['sapt total energy']\n",
        "        sapt_energies[1] = qcvars['sapt elst energy']\n",
        "        sapt_energies[2] = qcvars['sapt exch energy']\n",
        "        sapt_energies[3] = qcvars['sapt ind energy']\n",
        "        sapt_energies[4] = qcvars['sapt disp energy']\n",
        "        return (\n",
        "        record.molecule,\n",
        "        None,\n",
        "        None,\n",
        "        None,\n",
        "        None,\n",
        "        None,\n",
        "        record.molecule.atomic_numbers,\n",
        "        record.molecule.geometry * qcel.constants.bohr2angstroms,\n",
        "        None,\n",
        "        int(record.molecule.molecular_charge),\n",
        "        record.molecule.molecular_multiplicity,\n",
        "        sapt_energies,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def assemble_singlepoint_data_value_names():\n",
        "    return [\n",
        "        'qcel_molecule',\n",
        "        \"volume ratios\",\n",
        "        \"valence widths\",\n",
        "        \"radial moments <r^2>\",\n",
        "        \"radial moments <r^3>\",\n",
        "        \"radial moments <r^4>\",\n",
        "        \"Z\",\n",
        "        \"R\",\n",
        "        \"cartesian_multipoles\",\n",
        "        \"TQ\",\n",
        "        \"molecular_multiplicity\",\n",
        "        \"SAPT Energies\"\n",
        "    ]\n",
        "\n",
        "df = ds.compile_values(\n",
        "    value_call=assemble_singlepoint_data,\n",
        "    value_names=assemble_singlepoint_data_value_names(),\n",
        "    unpack=True,\n",
        ")\n",
        "pp(df.columns.tolist())\n",
        "df_sapt0 = df['psi4/SAPT0/cc-pvdz']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "CDD1QjxHpc"
      },
      "outputs": [],
      "source": [
        "def assemble_data(record):\n",
        "    record_dict = record.dict()\n",
        "    qcvars = record_dict[\"properties\"]\n",
        "    level_of_theory = f\"{record_dict['specification']['levels'][2]['method']}/{record_dict['specification']['levels'][2]['basis']}\"\n",
        "    CP_IE = qcvars['results']['cp_corrected_interaction_energy'] * h2kcalmol\n",
        "    NOCP_IE = qcvars['results'].get('nocp_corrected_interaction_energy', np.nan) * h2kcalmol\n",
        "    return (\n",
        "    record.initial_molecule,\n",
        "    CP_IE,\n",
        "    NOCP_IE,\n",
        "    record.initial_molecule.atomic_numbers,\n",
        "    record.initial_molecule.geometry * qcel.constants.bohr2angstroms,\n",
        "    int(record.initial_molecule.molecular_charge),\n",
        "    record.initial_molecule.molecular_multiplicity,\n",
        "    )\n",
        "\n",
        "def assemble_data_value_names():\n",
        "    return [\n",
        "        'qcel_molecule',\n",
        "        \"CP_IE\",\n",
        "        \"NOCP_IE\",\n",
        "        \"Z\",\n",
        "        \"R\",\n",
        "        \"TQ\",\n",
        "        \"molecular_multiplicity\"\n",
        "    ]\n",
        "\n",
        "df_mb = ds_mb.compile_values(\n",
        "    value_call=assemble_data,\n",
        "    value_names=assemble_data_value_names(),\n",
        "    unpack=True,\n",
        ")\n",
        "\n",
        "pp(df_mb.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "XT87RegBfm"
      },
      "outputs": [],
      "source": [
        "from cdsg_plot import error_statistics\n",
        "\n",
        "df_sapt0['sapt0 total energes'] = df_sapt0['SAPT Energies'].apply(lambda x: x[0] * h2kcalmol)\n",
        "df_plot = pd.DataFrame(\n",
        "    {\n",
        "        \"qcel_molecule\": df_mb[\"psi4/pbe/6-31g*\"][\"qcel_molecule\"],\n",
        "        \"HF/6-31G*\": df_mb[\"psi4/hf/6-31g*\"][\"CP_IE\"],\n",
        "        \"PBE/6-31G*\": df_mb[\"psi4/pbe/6-31g*\"][\"CP_IE\"],\n",
        "        'SAPT0/cc-pvdz': df_sapt0['sapt0 total energes'].values,\n",
        "    }\n",
        ")\n",
        "print(df_plot)\n",
        "id = [int(i[7:]) for i in df_plot.index]\n",
        "df_plot['id'] = id\n",
        "df_plot.sort_values(by='id', inplace=True, ascending=True)\n",
        "df_plot['reference'] = ref_IEs\n",
        "df_plot['SAPT0/aug-cc-pvdz'] = sapt0_adz\n",
        "df_plot['HF/6-31G* error'] = (df_plot['HF/6-31G*'] - df_plot['reference']).astype(float)\n",
        "df_plot['PBE/6-31G* error'] = (df_plot['PBE/6-31G*'] - df_plot['reference']).astype(float)\n",
        "df_plot['SAPT0/cc-pvdz error'] = (df_plot['SAPT0/cc-pvdz'] - df_plot['reference']).astype(float)\n",
        "df_plot['SAPT0/aug-cc-pvdz error'] = (df_plot['SAPT0/aug-cc-pvdz'] - df_plot['reference']).astype(float)\n",
        "pd.set_option('display.max_rows', None)\n",
        "print(df_plot[['PBE/6-31G*', 'SAPT0/cc-pvdz', 'reference', \"SAPT0/aug-cc-pvdz\"]])\n",
        "print(df_plot[['PBE/6-31G* error', 'SAPT0/cc-pvdz error', \"SAPT0/aug-cc-pvdz error\"]].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "6ziYQ8PdtF"
      },
      "source": [
        "# Plotting the interaction energy errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "dRiuyCtOh1"
      },
      "outputs": [],
      "source": [
        "error_statistics.violin_plot(\n",
        "    df_plot,\n",
        "    df_labels_and_columns={\n",
        "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
        "        \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
        "        # \"B3LYP/6-31G*\": \"B3LYP/6-31G* error\",\n",
        "        \"SAPT0/cc-pvdz\": \"SAPT0/cc-pvdz error\",\n",
        "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
        "    },\n",
        "    output_filename=\"S22-IE.png\",\n",
        "    figure_size=(6, 6),\n",
        "    x_label_fontsize=16,\n",
        "    ylim=(-15, 15),\n",
        "    rcParams={},\n",
        "    usetex=False,\n",
        "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "NoxyyvkpUK"
      },
      "source": [
        "# QCMLForge\n",
        "\n",
        "## AP-Net2 inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "8jtfD3m3S4"
      },
      "outputs": [],
      "source": [
        "import apnet_pt\n",
        "from apnet_pt.AtomPairwiseModels.apnet2 import APNet2Model\n",
        "from apnet_pt.AtomModels.ap2_atom_model import AtomModel\n",
        "\n",
        "atom_model = AtomModel().set_pretrained_model(model_id=0)\n",
        "ap2 = APNet2Model(atom_model=atom_model.model).set_pretrained_model(model_id=0)\n",
        "ap2.atom_model = atom_model.model\n",
        "apnet2_ies_predicted = ap2.predict_qcel_mols(\n",
        "    mols=df_plot['qcel_molecule'].tolist(),\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "nxmLPrfAfx"
      },
      "outputs": [],
      "source": [
        "# AP-Net2 IE\n",
        "df_plot['APNet2'] = np.sum(apnet2_ies_predicted, axis=1)\n",
        "df_plot['APNet2 error'] = (df_plot['APNet2'] - df_plot['reference']).astype(float)\n",
        "print(df_plot.sort_values(by='APNet2 error', ascending=True)[['APNet2', 'reference']])\n",
        "error_statistics.violin_plot(\n",
        "    df_plot,\n",
        "    df_labels_and_columns={\n",
        "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
        "        \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
        "        \"SAPT0/cc-pvdz\": \"SAPT0/cc-pvdz error\",\n",
        "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
        "        \"APNet2\": \"APNet2 error\",\n",
        "    },\n",
        "    output_filename=\"S22-IE-AP2.png\",\n",
        "    rcParams={},\n",
        "    usetex=False,\n",
        "    figure_size=(4, 4),\n",
        "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "XtMJQEokjd"
      },
      "outputs": [],
      "source": [
        "# Training models on new QM data: Transfer Learning\n",
        "\n",
        "from apnet_pt import pairwise_datasets\n",
        "\n",
        "ds2 = pairwise_datasets.apnet2_module_dataset(\n",
        "    root=\"data_dir\",\n",
        "    spec_type=None,\n",
        "    atom_model=atom_model,\n",
        "    qcel_molecules=df_plot['qcel_molecule'].tolist(),\n",
        "    energy_labels=[np.array([i]) for i in df_plot['reference'].tolist()],\n",
        "    skip_compile=True,\n",
        "    force_reprocess=True,\n",
        "    atomic_batch_size=8,\n",
        "    prebatched=False,\n",
        "    in_memory=True,\n",
        "    batch_size=4,\n",
        ")\n",
        "print(ds2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "4wjE6QG52G"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "xXslqNQSRI"
      },
      "outputs": [],
      "source": [
        "# Transfer Learning APNet2 model on computed QM data\n",
        "ap2.train(\n",
        "    dataset=ds2,\n",
        "    n_epochs=50,\n",
        "    transfer_learning=True,\n",
        "    skip_compile=True,\n",
        "    model_path=\"apnet2_transfer_learning.pt\",\n",
        "    split_percent=0.8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "KPOeFMBhWm"
      },
      "outputs": [],
      "source": [
        "# AP-Net2 IE\n",
        "apnet2_ies_predicted_transfer = ap2.predict_qcel_mols(\n",
        "    mols=df_plot['qcel_molecule'].tolist(),\n",
        "    batch_size=16,\n",
        ")\n",
        "df_plot['APNet2 transfer'] = np.sum(apnet2_ies_predicted_transfer, axis=1)\n",
        "df_plot['APNet2 transfer error'] = (df_plot['APNet2 transfer'] - df_plot['reference']).astype(float)\n",
        "\n",
        "error_statistics.violin_plot(\n",
        "    df_plot,\n",
        "    df_labels_and_columns={\n",
        "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
        "        \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
        "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
        "        \"APNet2\": \"APNet2 error\",\n",
        "        \"APNet2 transfer\": \"APNet2 transfer error\",\n",
        "    },\n",
        "    output_filename=\"S22-IE-AP2.png\",\n",
        "    rcParams={},\n",
        "    usetex=False,\n",
        "    figure_size=(6, 4),\n",
        "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "M3Q6tUC2AJ"
      },
      "source": [
        "## $\\Delta$AP-Net2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "ROLVxSHnj2"
      },
      "outputs": [],
      "source": [
        "from apnet_pt.pt_datasets.dapnet_ds import dapnet2_module_dataset_apnetStored\n",
        "\n",
        "delta_energies = df_plot['HF/6-31G* error'].tolist()\n",
        "\n",
        "# Only operates in pre-batched mode\n",
        "ds = dapnet2_module_dataset_apnetStored(\n",
        "    root=\"data_dir\",\n",
        "    r_cut=5.0,\n",
        "    r_cut_im=8.0,\n",
        "    spec_type=None,\n",
        "    max_size=None,\n",
        "    force_reprocess=True,\n",
        "    batch_size=2,\n",
        "    num_devices=1,\n",
        "    skip_processed=False,\n",
        "    skip_compile=True,\n",
        "    print_level=2,\n",
        "    in_memory=True,\n",
        "    m1=\"HF/6-31G*\",\n",
        "    m2=\"CCSD(T)/CBS\",\n",
        "    qcel_molecules=df_plot['qcel_molecule'].tolist(),\n",
        "    energy_labels=delta_energies,\n",
        ")\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "jfEVLnbL5w"
      },
      "outputs": [],
      "source": [
        "from apnet_pt.AtomPairwiseModels.dapnet2 import dAPNet2Model\n",
        "\n",
        "dap2 = dAPNet2Model(\n",
        "    atom_model=AtomModel().set_pretrained_model(model_id=0),\n",
        "    apnet2_model=APNet2Model().set_pretrained_model(model_id=0).set_return_hidden_states(True),\n",
        ")\n",
        "dap2.train(\n",
        "    ds,\n",
        "    n_epochs=50,\n",
        "    skip_compile=True,\n",
        "    split_percent=0.6,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "BbSVmmebsN"
      },
      "outputs": [],
      "source": [
        "dAPNet2_ies_predicted_transfer = dap2.predict_qcel_mols(\n",
        "    mols=df_plot['qcel_molecule'].tolist(),\n",
        "    batch_size=2,\n",
        ")\n",
        "df_plot['dAPNet2'] = dAPNet2_ies_predicted_transfer\n",
        "df_plot['HF/6-31G*-dAPNet2'] = df_plot['HF/6-31G*'] - df_plot['dAPNet2']\n",
        "print(df_plot[['dAPNet2', 'HF/6-31G*', 'HF/6-31G*-dAPNet2',  'reference']])\n",
        "df_plot['dAPNet2 error'] = (df_plot['HF/6-31G*-dAPNet2'] - df_plot['reference']).astype(float)\n",
        "\n",
        "error_statistics.violin_plot(\n",
        "    df_plot,\n",
        "    df_labels_and_columns={\n",
        "        \"HF/6-31G*\": \"HF/6-31G* error\",\n",
        "        \"PBE/6-31G*\": \"PBE/6-31G* error\",\n",
        "        \"SAPT0/aug-cc-pvdz\": \"SAPT0/aug-cc-pvdz error\",\n",
        "        \"APNet2\": \"APNet2 error\",\n",
        "        \"APNet2 transfer\": \"APNet2 transfer error\",\n",
        "        \"dAPNet2 HF/6-31G* to CCSD(T)/CBS\": \"dAPNet2 error\",\n",
        "    },\n",
        "    output_filename=\"S22-IE-AP2-dAP2.png\",\n",
        "    rcParams={},\n",
        "    usetex=False,\n",
        "    figure_size=(6, 4),\n",
        "    ylabel=r\"IE Error vs. CCSD(T)/CBS (kcal/mol)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "OVVcYRXWUA"
      },
      "outputs": [],
      "source": [
        "# Be careful with this for it can corrupt running status...\n",
        "# !ps aux | grep qcfractal | awk '{ print $2 }' | xargs kill -9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "H2TTLmA061"
      },
      "source": [
        "# The end..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "ULuCE0r8ED"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "p4_qcml2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
